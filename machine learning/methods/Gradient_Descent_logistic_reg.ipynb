{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4212dba-b6fa-4b6a-a5d5-a7b53eb26d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac3b990-42ab-4a66-a95e-9901b3c12bf6",
   "metadata": {},
   "source": [
    "- calculate and updata theta by gradien descent method\n",
    "$$J(\\theta) = \\frac{1}{m} \\overset{m}{\\underset{i=1}{\\sum}}[y_i log(h_{\\theta}(x_i)) + (1-y_i)log(1-h_{\\theta}(x_i)]$$\n",
    "$$\\theta_j := \\theta_j -  \\frac{\\alpha}{m}\\overset{m}{\\underset{i=1}{\\sum}}(h_{\\theta}(x_i) - y_i)x_{ij}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98d0ce5c-2e96-4165-82db-533c93152723",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_logit():\n",
    "    # input values\n",
    "    data_name=input(\"Enter the name of data file [(ex) sample1.csv] : \") # data name\n",
    "    coding_fm=int(input(\"Select the data Seperator(1 = ' ' or 2 = ','): \")) # data separator of training data\n",
    "    separator_fm={coding_fm ==1 : \" \"}.get(True, \",\")\n",
    "    header=input(\"Does the data have column header? (y/n) : \")\n",
    "    if(header==\"y\") :\n",
    "        trdata=pd.read_csv(data_name, sep=separator_fm) # loading data with header\n",
    "        res_pos = input(f'Enter the column name of response variable among {list(trdata.columns)} : ')\n",
    "        y = trdata[res_pos]\n",
    "        X = trdata.drop(res_pos, axis = 1)\n",
    "\n",
    "    else : \n",
    "        trdata=pd.read_csv(data_name, sep=separator_fm, header=None) # loading data without header\n",
    "        res_pos = int(input(f'Enter the column position of the response variable : \\n [from 1 to {trdata.shape[1]}] : '))\n",
    "        X_index = []\n",
    "        for i in range(len(trdata.columns)): \n",
    "            if i == res_pos-1 : continue\n",
    "            X_index.append(i)\n",
    "\n",
    "        # define response variable and predictor\n",
    "        y = trdata.iloc[:,res_pos-1]\n",
    "        X = trdata.iloc[:,X_index]\n",
    "    \n",
    "    theta = [float(x) for x in input(f'Enter {X.shape[1] + 1} number of starting point of gradient descent : '\n",
    "                                    ).split(',')]\n",
    "    learning_rate = float(input('Enter the learning rate of gradient descent between 0 and 1 : '))\n",
    "    max_iter = int(input('Enter the max_iteration limit : '))\n",
    "    threshold = float(input('Enter the threshold of gradient descent : '))\n",
    "    out_name=input(\"Enter the output file name to export [(ex) result.txt] : \")\n",
    "    \n",
    "    # add constant in X variable\n",
    "    X.insert(loc = 0 , column= 'constant', value = np.ones(trdata.shape[0]))\n",
    "    \n",
    "    \n",
    "    theta_history = pd.DataFrame(theta)\n",
    "    # gradient descent\n",
    "    for iter in range(1,max_iter):\n",
    "        ypred = 1/(1+np.exp(-X@theta))\n",
    "        update = learning_rate * (1/len(X)) * ((ypred - y).transpose() @ X)\n",
    "        theta = np.array(theta - update)\n",
    "        theta_history.insert(loc = iter, column = f'{iter}', value = theta)\n",
    "        if np.all(np.abs(update) <= threshold):\n",
    "            break\n",
    "            \n",
    "    # sm logistic regression\n",
    "    mod = sm.Logit(y,X)\n",
    "    res = mod.fit()\n",
    "    \n",
    "    # write file\n",
    "    f = open(out_name,'w+')\n",
    "    f.write('Coefficients by Gradient Descent Method\\n')\n",
    "    f.write('-------------\\n')\n",
    "    f.write(f'Constant: {round(theta[0],3)}\\n')\n",
    "    for i in range(1,len(theta)):\n",
    "        f.write(f'Beta {i} : {round(theta[i],3)}\\n')\n",
    "\n",
    "    f.write('Coefficients by STATMODELS \\n')\n",
    "    f.write('-------------\\n')\n",
    "    f.write(f'Constant: {round(list(res.params)[0],3)}\\n')\n",
    "    for i in range(1,len(res.params)):\n",
    "        f.write(f'Beta {i} : {round(list(res.params)[i],3)}\\n')\n",
    "    f.close()\n",
    "\n",
    "    # print results\n",
    "    print('------------------------')\n",
    "    print('file has been saved')\n",
    "    print('result is\\n\\n')\n",
    "    \n",
    "    r = open(out_name,'r')\n",
    "    for line in r.readlines():\n",
    "        print(line)\n",
    "    r.close()\n",
    "    return {'gradient_decent_beta' : theta,'history' : theta_history, 'OLS_beta' : res.params}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "821b6512-f26b-4789-b9f7-3a9a8e9e27b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the name of data file [(ex) sample1.csv] :  sample1.csv\n",
      "Select the data Seperator(1 = ' ' or 2 = ','):  2\n",
      "Does the data have column header? (y/n) :  y\n",
      "Enter the column name of response variable among ['x1', 'x2', 'y'] :  y\n",
      "Enter 3 number of starting point of gradient descent :  0,0,0\n",
      "Enter the learning rate of gradient descent between 0 and 1 :  0.3\n",
      "Enter the max_iteration limit :  10000\n",
      "Enter the threshold of gradient descent :  0.0001\n",
      "Enter the output file name to export [(ex) result.txt] :  result.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.283800\n",
      "         Iterations 8\n",
      "------------------------\n",
      "file has been saved\n",
      "result is\n",
      "\n",
      "\n",
      "Coefficients by Gradient Descent Method\n",
      "\n",
      "-------------\n",
      "\n",
      "Constant: 0.166\n",
      "\n",
      "Beta 1 : 2.8\n",
      "\n",
      "Beta 2 : 2.796\n",
      "\n",
      "Coefficients by STATMODELS \n",
      "\n",
      "-------------\n",
      "\n",
      "Constant: 0.168\n",
      "\n",
      "Beta 1 : 2.822\n",
      "\n",
      "Beta 2 : 2.819\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = gradient_descent_logit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
